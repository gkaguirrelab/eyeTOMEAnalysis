%% set paths and make directories

%% hard coded parameters
verbosity = 'full'; % Set to none to make the demo silent
TbTbToolboxName = 'transparentTrack';

% define path parameters
pathParams.dataSourceDirRoot = fullfile('~','Dropbox (Aguirre-Brainard Lab)','TOME_data');
pathParams.dataOutputDirRoot = fullfile('~','Dropbox (Aguirre-Brainard Lab)','TOME_processing');
pathParams.projectSubfolder = 'CameraCalibration';
pathParams.eyeTrackingDir = 'EyeTracking';
pathParams.subjectID = 'CameraCal_0001';
pathParams.sessionDate = '010318';
pathParams.runName = 'checkerBoard_2.5mm_run01';

% place to save the final camera calibration matrix
cameraCalibrationFileName = fullfile('~','Dropbox (Aguirre-Brainard Lab)','TOME_materials','hardwareSpecifications','liveTrackAVfMRI','cameraCalibration','liveTrackAV_cameraCalibration.mat');

%% TbTb configuration
% We will suppress the verbose output, but detect if there are deploy
% errors and if so stop execution
tbConfigResult=tbUse(TbTbToolboxName,'reset','full','verbose',false);
if sum(cellfun(@sum,extractfield(tbConfigResult, 'isOk')))~=length(tbConfigResult)
    error('There was a tb deploy error. Check the contents of tbConfigResult');
end
tbSnapshot=tbDeploymentSnapshot(tbConfigResult,'verbose',false);
clear tbConfigResult


%% Prepare paths and directories

% define full paths for input and output
pathParams.dataSourceDirFull = fullfile(pathParams.dataSourceDirRoot, pathParams.projectSubfolder, ...
    pathParams.subjectID, pathParams.sessionDate, pathParams.eyeTrackingDir);
pathParams.dataOutputDirFull = fullfile(pathParams.dataOutputDirRoot, pathParams.projectSubfolder, ...
    pathParams.subjectID, pathParams.sessionDate, pathParams.eyeTrackingDir);


%% Run the analysis pipeline
 runVideoPipeline( pathParams, ...
     'verbosity', verbosity, 'tbSnapshot',tbSnapshot, 'useParallel',true, ...
     'catchErrors', false,'lastStage','deinterlaceVideo');

% Define the video file name
videoInFileName = fullfile(pathParams.dataOutputDirRoot,pathParams.projectSubfolder,pathParams.subjectID,pathParams.sessionDate,pathParams.eyeTrackingDir,[pathParams.runName '_gray.avi']);

% Open a video object for reading
videoInObj = VideoReader(videoInFileName);

% get video dimensions
videoSizeX = videoInObj.Width;
videoSizeY = videoInObj.Height;

nFrames = floor(videoInObj.Duration*videoInObj.FrameRate);

%% List of frames to use for calibration
% We want about 10-20 "poses" of the calibration grid. The frame numbers
% listed here correspond to the raw video, so we multiply x2 to obtain
% the frame number after de-interlacing.
calibrationFrames = [2140 2167 2897 3989 4565 4764 5420 5931 6390 6732 6895 7337 7683 8096 8779 9129 9285 9471 9672 9832 9983 10043 10094 10320 10533].*2;

% Loop through the frames
frameIndex = 1;
for ii=1:nFrames
    
    % read the source video frame into memory
    sourceFrame = readFrame(videoInObj);

    % check if this is a frame we are going to use. If so, write it out.
    if sum(ii== calibrationFrames) == 1
        sourceFrame = rgb2gray (sourceFrame);
        imageFileNames{frameIndex} = fullfile(pathParams.dataOutputDirRoot,pathParams.projectSubfolder,pathParams.subjectID,pathParams.sessionDate,pathParams.eyeTrackingDir,[pathParams.runName '_frame_' num2str(ii) '.png']);
        imwrite(sourceFrame,imageFileNames{frameIndex})
        frameIndex = frameIndex + 1;
    end    
end

clear videoInObj


%-------------------------------------------------------
% The code below was auto-generated by cameraCalibrator app on 03-Jan-2018
%-------------------------------------------------------

% Detect checkerboards in images
[imagePoints, boardSize, imagesUsed] = detectCheckerboardPoints(imageFileNames);
imageFileNames = imageFileNames(imagesUsed);

% Read the first image to obtain image size
originalImage = imread(imageFileNames{1});
[mrows, ncols, ~] = size(originalImage);

% Generate world coordinates of the corners of the squares
squareSize = 2.500000e+00;  % in units of 'millimeters'
worldPoints = generateCheckerboardPoints(boardSize, squareSize);

% Calibrate the camera
[cameraParams, imagesUsed, estimationErrors] = estimateCameraParameters(imagePoints, worldPoints, ...
    'EstimateSkew', false, 'EstimateTangentialDistortion', false, ...
    'NumRadialDistortionCoefficients', 2, 'WorldUnits', 'millimeters', ...
    'InitialIntrinsicMatrix', [], 'InitialRadialDistortion', [], ...
    'ImageSize', [mrows, ncols]);

% Report the intrinsic matrix:
fprintf('Camera intrinsic matrix: \n');
cameraParams.IntrinsicMatrix'
fprintf('Note that the x and y values need to be swapped to match our image coordinate convention\n');
fprintf('\n');
fprintf('Radial distortion params k1, k2: \n');
cameraParams.RadialDistortion

% Save the cameraParams file
save(cameraCalibrationFileName,'cameraParams');
